# -*- coding: utf-8 -*-
"""Exercise 4.3 Evaluating model accuracy on validation dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i50F9OPI9Kao3S0z72eB7SYw9SlE37n7

## Exercise 4.3 Evaluating model accuracy on validation dataset

In this exercise, you will use the same titanic dataset from the previous exercises. You can download the dataset from the following link:

[titanic_all_numeric.csv](https://drive.google.com/file/d/11nuYS-l3EXCsGJt81y4YTt3oTnFGaB68/view?usp=drive_link)

The data is pre-loaded into a pandas DataFrame called `df`. The `predictors` and `target` values are also pre-defined.

Now it's your turn to monitor model accuracy with a validation data set. A model definition has been provided as `model`.

Your job is to add the code to compile it and then fit it. You'll check the validation score in each epoch.

## Instructions

* Compile your model using `'adam'` as the optimizer and `'categorical_crossentropy'` for the loss. To see what fraction of predictions are correct (the accuracy) in each epoch, specify the additional keyword argument `metrics=['accuracy']` in `model.compile()`.
* Fit the model using the predictors and target. Create a validation split of `30%` (or `0.3`). This will be reported in each epoch.

## Code

Load data and convert the data to NumPy array:
"""

import numpy as np
import pandas as pd
from tensorflow.keras.utils import to_categorical

# Load csv file into the dataframe: df
df = pd.read_csv("titanic_all_numeric.csv")

# Convert the boolean values of the 'age_was_missing' column to integer
df.age_was_missing = df.age_was_missing.replace({True: 1, False: 0})

# Create predictors NumPy array: predictors
predictors = df.drop(['survived'], axis=1).values

# Save the number of columns in predictors: n_cols
n_cols = predictors.shape[1]

# Convert the target to categorical: target
target = to_categorical(df['survived'])

# Define the input shape: input_shape
input_shape = (n_cols,)

"""Create a neural network for a classification task"""

from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential

def get_new_model(input_shape):
  # Set up the model
  model = Sequential()
  model.add(Dense(100, activation='relu', input_shape=input_shape))
  model.add(Dense(100, activation='relu'))
  model.add(Dense(2, activation='softmax'))

  return model

"""Compile and fit the model with a validation dataset:"""

# Specify the model
model = get_new_model(input_shape)

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Fit the model
hist = model.fit(predictors,
                 target,
                 validation_split=0.3,
                 epochs=1,          # chạy 1 epoch để có log giống yêu cầu
                 verbose=1)

"""The ouput should be:

20/20 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.5932 - loss: 1.0253 - val_accuracy: 0.6567 - val_loss: 0.8172

"""